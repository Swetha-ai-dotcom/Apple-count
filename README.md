# Apple Detection in Video Using YOLOv5

This project demonstrates the use of the YOLOv5 object detection model to detect apples in a video of an apple orchard. The video is processed frame by frame, and apples are identified using a custom-trained YOLOv5 model. The detected apples are counted, and bounding boxes are drawn around each apple in the video. The processed video is saved and can be downloaded.

---

### Prerequisites:

- **Python 3.x**
- **Google Colab** (for cloud-based execution)

#### Required Python Libraries:
- `torch`
- `cv2` (OpenCV)
- `IPython.display`
- `google.colab`
- `ultralytics/yolov5` (for the YOLOv5 model)

---

### Steps to Run:

1. **Mount Google Drive:**
   The code begins by mounting Google Drive to access the video file stored in it. Ensure your video file path is correct in Google Drive.

2. **Load YOLOv5 Model:**
   The YOLOv5 pre-trained model (or custom-trained model) is loaded using the `torch.hub.load` function. The model weights are specified by the `model_weights` variable. If you have custom-trained weights, replace the path accordingly.

3. **Video Loading and Processing:**
   The video is read using OpenCV (`cv2.VideoCapture`) from the specified path. The video is processed frame by frame, and apples are detected using the YOLOv5 model. Bounding boxes are drawn around detected apples, and the frame is saved to an output video file.

4. **Display Results in Google Colab:**
   Every 10th frame is displayed in the Colab output as the video is processed. This helps visualize the progress of the detection process.

5. **Download the Processed Video:**
   After the video processing is complete, the output video file is available for download.

---

### Output:
- The script outputs a processed video with bounding boxes around detected apples.
- A summary of the total number of apples detected in the video is printed at the end.
- The processed video is saved as `apple_detection_output.mp4` and is available for download.

---

### How to Use:

1. Upload your video to Google Drive.
2. Modify the `video_path` in the code to match the location of your video in Google Drive.
3. Run the script in Google Colab.
4. After processing, download the output video by clicking the download link generated by `files.download(output_video_path)`.

---

### Requirements:

You may need to install the following libraries if they are not already available:

```bash
!pip install torch
!pip install opencv-python-headless
!pip install yolov5
```

---

### Troubleshooting:

- **Error: Could not open video:**
  - Ensure the video path is correct, and the video file is accessible in Google Drive.

- **Model detection issues:**
  - If the model doesn't detect apples correctly, you may need to retrain the YOLOv5 model with better data or fine-tune it.
